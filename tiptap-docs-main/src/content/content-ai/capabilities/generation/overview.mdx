---
title: Integrate AI into your editor
meta:
  title: AI Generation | Tiptap Content AI
  description: Integrate AI features into your editor like smart autocompletion, image generation and more. Read about it in our docs.
  category: Content AI
---

import { CodeDemo } from '@/components/CodeDemo'
import { Callout } from '@/components/ui/Callout'

Integrate the AI Generation extension into your Tiptap Editor with just a couple of lines of code. This extension equips you with a set of AI-enhanced features including pre-built commands, prompt customization, image generation, and smart autocompletion.

Add your own custom commands on top and even integrate your own proprietary LLM to create a unique user experience.

<CodeDemo isPro path="/Extensions/AiCommands" />

<Callout title="Subscription required" variant="warning">
    This extension requires a valid subscription. To install the extension, you need [access to our
    private registry](/guides/pro-extensions).
</Callout>

## AI Generation features

- [Pre-configured default commands](/content-ai/capabilities/generation/text-generation)
- [Autocompletion for efficient editing](/content-ai/capabilities/generation/text-generation/autocompletion)
- Real-time streaming for commands
- Compatibility with various OpenAI models (e.g., gpt-3.5-turbo, gpt-4, gpt-4o, dall-e-3)
- [Create your own prompts and commands](/content-ai/capabilities/generation/text-generation/custom-commands)
- [Custom LLM integration for business accounts](/content-ai/capabilities/generation/custom-llms)

## How it works

Integrate [OpenAI](/content-ai/capabilities/generation/install) or your own [Custom LLM](/content-ai/capabilities/generation/custom-llms) with your Tiptap Editor. The extension covers both, the client and server-side implementations. Hereâ€™s the user experience:

1. Highlight text in the editor and apply an AI command.
2. Your selection, the chosen action, and any options are sent to our cloud service.
3. We generate a prompt and engage OpenAI on your behalf.
4. The AI's response is then directly inserted or streamed into your editor.

By default, this utilizes our backend service, but there are options for advanced scenarios including custom backends and LLMs.
